# -*- coding: utf-8 -*-
"""NrlNtwrkClsfierFashMINST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QeX9xc0_C0iCiUe18mY2qanpjfLWsYwZ
"""

# Importing necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy

# Load the Fashion MNIST dataset
fashion_mnist = tf.keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Normalize the data (important!)
x_train = x_train / 255.0
x_test = x_test / 255.0

# Show the shape of data
print(f"Training set: {x_train.shape}, Labels: {y_train.shape}")
print(f"Test set: {x_test.shape}, Labels: {y_test.shape}")

# Map class labels to names
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Display the first 9 images with labels
plt.figure(figsize=(10, 6))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(class_names[y_train[i]])
    plt.axis('off')
plt.tight_layout()
plt.show()

# to see the vector of inputs to our ML model
sample_image = x_train[0]
sample_label = y_train[0]

# Flatten the image
flattened_vector = sample_image.flatten()

print(f"Original shape: {sample_image.shape}")
print(f"Flattened shape: {flattened_vector.shape}")
print(f"Label: {class_names[sample_label]}")

# Print the flattened input vector
# This shows the exact numeric input that our neural network will receive for that image.
np.set_printoptions(precision=2, linewidth=150)
# print(flattened_vector)
print(flattened_vector.reshape(-1,28))

# the model (with tensorflow)
model = Sequential([
    Flatten(input_shape=(28, 28)),           # Flatten the 28x28 images to 1D
    Dense(128, activation='relu'),           # First hidden layer
    Dense(64, activation='relu'),            # Second hidden layer
    Dense(10, activation='softmax')          # Output layer (10 classes)
])

# compile
model.compile(
    optimizer=Adam(),
    loss=SparseCategoricalCrossentropy(),   # because labels are integers (not one-hot)
    metrics=['accuracy']
)

# train
history = model.fit(
    x_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.1,   # Reserve 10% of training data for validation
    verbose=2
)

# Predict labels for the test set
y_pred = model.predict(x_test)
pred_labels = np.argmax(y_pred, axis=1)

# Evaluate on the test set
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)

# track misclassified indices
misclassified = np.where(pred_labels != y_test)[0]

# let's see some of the misclassified images
plt.figure(figsize=(12, 6))
for i, idx in enumerate(misclassified[:9]):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_test[idx], cmap='gray')
    plt.title(f"True: {class_names[y_test[idx]]}\nPred: {class_names[pred_labels[idx]]}")
    plt.axis('off')
plt.tight_layout()
plt.suptitle("Misclassified Images", fontsize=16)
plt.subplots_adjust(top=0.88)
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict labels for test set
y_pred = model.predict(x_test)
pred_labels = np.argmax(y_pred, axis=1)

cm = confusion_matrix(y_test, pred_labels)  # Compute the confusion matrix

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
plt.figure(figsize=(10, 8))
disp.plot(cmap='Blues', xticks_rotation=45)
plt.title("Confusion Matrix")
plt.grid(False)
plt.show()

